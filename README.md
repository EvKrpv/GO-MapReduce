# GO-MapReduce
Frequency Counter
Проект для частотного анализа слов в больших текстовых файлах с использованием подхода MapReduce. Программа находит N самых частых слов в файле, работая в условиях ограниченной памяти.

Описание
Программа читает текстовый файл частями (чанками), разбивает текст на слова, подсчитывает частоту встречаемости каждого слова и возвращает топ-N наиболее часто встречающихся слов. Реализована с использованием конкурентной обработки данных.

Архитектура
Проект построен по принципу MapReduce и состоит из следующих компонентов:

Чтение файла частями (readChunks): читает файл блоками заданного размера

Map-фаза (mapWords): токенизирует текст и подсчитывает частоту слов в каждом чанке

Reduce-фаза (reduceWordCounts): объединяет результаты от всех мапперов

Сортировка результатов (getTopWords): выбирает топ-N самых частых слов

Структура проекта
text
processor/          # Пакет с основной логикой обработки
    processor.go    # Реализация MapReduce пайплайна
    processor_test.go # Тесты
main.go             # CLI интерфейс
go.mod              # Зависимости Go
Требования
Go 1.19 или выше

Установка
bash
go mod init Freq_Counter
Использование
Запуск из командной строки
bash
go run main.go <путь_к_файлу>
Параметры
chunkSize: размер чанка для чтения (по умолчанию 64 КБ)

topN: количество возвращаемых самых частых слов (по умолчанию 10)

Пример
bash
go run main.go large_text_file.txt
Вывод:

text
Top words:
go: 100
goroutine: 50
channel: 30
mutex: 20
heap: 15
...
Тестирование
Запуск тестов:
```
bash
go test ./...
Тесты покрывают:
```
Обработку файла целиком

Выбор топ-N слов

Объединение результатов от нескольких мапперов

Корректность чтения файла частями

Основные функции
ProcessFile(file io.ReadCloser, chunkSize int, topN int) ([]WordFreq, error)
Основная функция для обработки файла. Принимает:

file: читаемый файл

chunkSize: размер блока для чтения

topN: количество возвращаемых самых частых слов

Возвращает срез структур WordFreq, отсортированный по убыванию частоты.

Структура WordFreq
go
```
type WordFreq struct {
    Word  string
    Count int
}
```
Особенности реализации
Эффективное использование памяти: файл читается частями, не загружается целиком в память

Конкурентная обработка: используются горутины для параллельной обработки чанков

Токенизация с нормализацией: слова приводятся к нижнему регистру, удаляются не-буквенные символы

Масштабируемость: количество мапперов настраивается в коде

Ограничения
Максимальный размер чанка: 64 КБ (настраивается в константе)

Количество мапперов: 4 (фиксировано в коде)

Поддерживаются только буквенные символы (unicode.IsLetter)


